{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset: BL_dataset.csv of size (409, 877)\n",
      "Adding target endpoint to dataset...\n",
      "Conclusion_micro\n",
      "poly                 146\n",
      "mono_GAS             114\n",
      "mono_gramneg_aero     18\n",
      "poly_STAU             13\n",
      "poly_GBS              13\n",
      "mono_STAU             13\n",
      "poly_GAS              12\n",
      "mono_CLOST            10\n",
      "mono_GCS               8\n",
      "poly_CLOST             7\n",
      "poly_GGS               7\n",
      "mono_GGS               7\n",
      "poly_GCS               6\n",
      "mono_strep_other       4\n",
      "mono_anaerob           3\n",
      "mono_GBS               2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = \"Conclusion_micro\"\n",
    "\n",
    "path_data = \"../../results/00_datasets\"\n",
    "!mkdir -p ../../results/10_preprocessed\n",
    "\n",
    "### Read time-dissected datasets\n",
    "sets = \"BL_dataset.csv\"\n",
    "\n",
    "### Load datasets\n",
    "data = pd.read_csv(os.path.join(path_data, \"time_dissection\", sets), low_memory=False)\n",
    "print(f\"Reading dataset: {sets} of size {data.shape}\")\n",
    "\n",
    "### Read in TARGET\n",
    "data_target = pd.read_csv(f\"{path_data}/TARGET_dataset.csv\", low_memory=False)\n",
    "\n",
    "### Concat TARGET\n",
    "print(f\"Adding target endpoint to dataset...\")\n",
    "data_target2 = data_target[[\"PATIENT_ID\",target]]\n",
    "data = pd.merge(data, data_target2, on='PATIENT_ID', how = \"inner\")\n",
    "\n",
    "\n",
    "print(data[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize 'Conclusion_micro' to only GAS vs non-GAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 878)\n",
      "Conclusion_micro\n",
      "0    283\n",
      "1    126\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2 catagories: GAS, non-GAS (=\"other\")\n",
    "conc_micro_dic = {\"GAS\": [\"mono_GAS\", \"poly_GAS\"],\n",
    "                  \"OTHER\":[\"poly\",\"poly_CLOST\",\"poly_STAU\",'poly_C+LOST', 'poly_GBS', 'mono_gramneg_aero', 'mono_STAU', 'poly_GCS', 'mono_anaerob','mono_CLOST', \"nan\", 'mono_GCS', 'poly_GGS', 'mono_strep_other', 'mono_GGS', 'mono_GBS']}\n",
    "for i in conc_micro_dic.keys():\n",
    "    data.replace(conc_micro_dic[i], i, inplace=True)\n",
    "data[target].fillna(value=\"OTHER\", inplace=True)\n",
    "\n",
    "### BINARIZE\n",
    "data[target].replace(\"GAS\", 1, inplace=True)\n",
    "data[target].replace(\"OTHER\", 0, inplace=True)\n",
    "\n",
    "print(data.shape)\n",
    "print(data[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "- Remove patients with NaN in target label\n",
    "- Remove biasing/unnecessary labels (DATE/TIME columns, other_bact_sample_x, other_bact_blood_x)\n",
    "- Clean up hospital names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusion_micro\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove patients with NaN in target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed patients with NaN in target label: 0\n"
     ]
    }
   ],
   "source": [
    "### Remove patients with NaN in target label ###\n",
    "pats0=df.shape[0]\n",
    "df.dropna(axis=0, subset=[target], inplace=True)\n",
    "print(f\"Removed patients with NaN in target label: {pats0-df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove biasing/unnecessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing biasing/unnecessary variables:\n",
      "\tIndex(['DATE_FIRST_ADMISSION', 'HOSPITAL_FORST_ADMIS', 'DATE_DIAGNOSIS',\n",
      "       'DATE_SPEC_HOSP', 'DATE_ICU_ADMISSION', 'date_of_data_2',\n",
      "       'date_specimen_sample_1', 'date_specimen_sample_2',\n",
      "       'date_specimen_sample_3', 'date_specimen_sample_4',\n",
      "       ...\n",
      "       'hospital_surgery_8', 'hospital_surgery_9', 'hospital_surgery_10',\n",
      "       'hospital_surgery_11', 'hospital_surgery_12', 'hospital_surgery_13',\n",
      "       'hospital_surgery_14', 'hospital_surgery_15', 'HOSPITAL_PREOP',\n",
      "       'TIME_DISCHARGE'],\n",
      "      dtype='object', length=103)\n",
      "\tNumber of removed unnecessary variables: 103\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removing biasing/unnecessary variables:\")\n",
    "### remove DATE* and TIME* columns ###\n",
    "vars0=df.shape[1]\n",
    "removeLabels = [\"date\", \"time\", \"hospital\"]\n",
    "before=df.columns[df.columns.str.contains('|'.join(removeLabels), case=False, regex=True)]\n",
    "df.drop(df.columns[df.columns.str.contains('|'.join(removeLabels), case=False, regex=True)],\n",
    "        axis = 1, inplace=True)\n",
    "print(f\"\\t{before}\")\n",
    "\n",
    "### remove \"other_bact_sample_x\" ###\n",
    "## --> decided it was too messy\n",
    "before=df.columns[df.columns.str.contains(\"other_bact_sample\", case=False)]\n",
    "df.drop(df.columns[df.columns.str.contains(\"other_bact_sample\", case=False)],\n",
    "            axis=1, inplace = True)\n",
    "#print(f\"\\t{before}\")\n",
    "### remove \"other_bact_blood_x\" ###\n",
    "before=df.columns[df.columns.str.contains(\"other_bact_blood\", case=False)]\n",
    "df.drop(df.columns[df.columns.str.contains(\"other_bact_blood\", case=False)],\n",
    "        axis=1, inplace = True)\n",
    "#print(f\"\\t{before}\")\n",
    "print(f\"\\tNumber of removed unnecessary variables: {vars0-df.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove variables with missingess > 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed variables with a missingess of > 0.1: 13\n",
      "\n",
      "Removed variables: ['ALCOHOL', 'SMOKING', 'SKIN_ANAESTHESIA_PREOP', 'CREPITUS_PREOP', 'GAS_RADIOLOGY_PREOP', 'lactate_preop', 'glucose_preop', 'hgb_preop_d', 'hgb_preop_n', 'hgb_preop_s', 'PCT_BL', 'fibrinogen_BL', 'd_dimer_BL']\n"
     ]
    }
   ],
   "source": [
    "### Remove variables with missingess > 5 % ###\n",
    "before=df.columns\n",
    "var2 = df.shape[1]\n",
    "miss_thresh = 0.1\n",
    "dfbefore = df.copy()\n",
    "df.dropna(axis=1, thresh=round(df.shape[0]*(1-miss_thresh)), inplace=True)\n",
    "print(f\"Removed variables with a missingess of > {miss_thresh}: {var2 - df.shape[1]}\\n\")\n",
    "print(f\"Removed variables: {[var for var in before if var not in df.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inlcude septic shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3594812/2561803306.py:1: DtypeWarning: Columns (625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,758,759,760,761,762,763,764,765,766,767,768,769,1026,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1077,1078,1079,1080,1081,1082,1350,1352,1353,1357,1398,1399,1400,1413,1414,1415) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_allVars = pd.read_csv(f\"{path_data}/allFeatures_fullDataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "data_allVars = pd.read_csv(f\"{path_data}/allFeatures_fullDataset.csv\")\n",
    "\n",
    "df[\"shock_BL\"] = data_allVars.loc[df.index,\"shock_BL\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: (409, 762)\n",
      "Saving dataset...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final dataset size: {df.shape}\")\n",
    "### Save imputed dataset ###\n",
    "print(\"Saving dataset...\\n\\n\")\n",
    "dataset=sets.replace(\".\", \"_\").split(\"_\")[0]\n",
    "df.to_csv(os.path.join(f\"../../results/10_preprocessed/{dataset}_{target}_preprocessed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_permit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
